{"meta":{"title":"Hexo","subtitle":"","description":"","author":"Deacone","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"20200324_Flask工程模式注册日志","slug":"20200324_Flask工程模式注册日志","date":"2020-04-10T07:00:34.295Z","updated":"2020-04-10T07:00:34.297Z","comments":true,"path":"2020/04/10/20200324_Flask工程模式注册日志/","link":"","permalink":"http://yoursite.com/2020/04/10/20200324_Flask%E5%B7%A5%E7%A8%8B%E6%A8%A1%E5%BC%8F%E6%B3%A8%E5%86%8C%E6%97%A5%E5%BF%97/","excerpt":"","text":"Flask 工厂模式注册初始化logger工厂模式的意义引用官方解释： If you are already using packages and blueprints for your application (Modular Applications with Blueprints) there are a couple of really nice ways to further improve the experience. A common pattern is creating the application object when the blueprint is imported. But if you move the creation of this object into a function, you can then create multiple instances of this app later. So why would you want to do this? Testing. You can have instances of the application with different settings to test every case. Multiple instances. Imagine you want to run different versions of the same application. Of course you could have multiple instances with different configs set up in your webserver, but if you use factories, you can have multiple instances of the same application running in the same application process which can be handy. 大概意思是： 为了方便测试，你可以随心所欲的切换不同的配置实例来测试你的用例。 相同的应用，你可以利用不同的配置实例来进行初始化，达到运行不同版本应用的目的。 官方实例的应用(autoapp.py)： 12345678910111213def create_app(config_filename): app = Flask(__name__) app.config.from_pyfile(config_filename) from yourapplication.model import db db.init_app(app) from yourapplication.views.admin import admin from yourapplication.views.frontend import frontend app.register_blueprint(admin) app.register_blueprint(frontend) return app 初始化为了能让我们的日志初始化添加如下代码(autoapp.py)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071def register_logging(app): app.config.setdefault(\"LOG_PATH\", \"application.log\") log_formatter = \"%(asctime)s [%(thread)d:%(threadName)s] %(filename)s:%(module)s:%(funcName)s in %(lineno)d] [%(levelname)s]: %(message)s\" app.config.setdefault(\"LOG_FORMATTER\", log_formatter) app.config.setdefault(\"LOG_MAX_BYTES\", 50 * 1024 * 1024) app.config.setdefault(\"LOG_BACKUP_COUNT\", 10) app.config.setdefault(\"LOG_INTERVAL\", 1) app.config.setdefault(\"LOG_WHEN\", \"D\") app.config.setdefault(\"LOG_LEVEL\", \"INFO\") formatter = logging.Formatter(app.config[\"LOG_FORMATTER\"]) # 将日志输出到文件 # 指定间隔时间自动生成文件的处理器 # 实例化TimedRotatingFileHandler # interval是时间间隔， # backupCount是备份文件的个数，如果超过这个个数，就会自动删除 # when是间隔的时间单位，单位有以下几种： # S 秒 # M 分 # H 小时、 # D 天、 # W 每星期（interval==0时代表星期一） # midnight 每天凌晨 timed_rotating_file_handler = TimedRotatingFileHandler( filename=app.config[\"LOG_PATH\"], interval=app.config[\"LOG_INTERVAL\"], when=app.config[\"LOG_WHEN\"], backupCount=app.config[\"LOG_BACKUP_COUNT\"], encoding=\"utf-8\", ) timed_rotating_file_handler.setFormatter(formatter) # 设置文件里写入的格式 timed_rotating_file_handler.setLevel(app.config[\"LOG_LEVEL\"]) # StreamHandler stream_handler = StreamHandler() stream_handler.setFormatter(formatter) stream_handler.setLevel(app.config[\"LOG_LEVEL\"]) # SMTPHandler mail_handler = DelaySMTPHandler( mailhost=app.config[\"MAILHOST\"], credentials=app.config[\"CREDENTIALS\"], fromaddr=app.config[\"FROMADDR\"], toaddrs=app.config[\"TOADDRS\"], subject=app.config[\"SUBJECT\"], ) mail_handler.setLevel(logging.ERROR) mail_handler.setFormatter(formatter) # 删除默认的handler # app.logger.removeHandler(default_handler) # 设置logger for logger in ( app.logger, logging.getLogger(\"sqlalchemy\"), logging.getLogger(\"werkzeug\"), ): logger.addHandler(stream_handler) logger.addHandler(timed_rotating_file_handler) if os.getenv(\"FLASK_ENV\") == \"production\": logger.addHandler(mail_handler) # set logger for elk # stash_handler = logstash.LogstashHandler( # app.config.get('ELK_HOST'), # app.config.get('ELK_PORT') # ) # root_logger.addHandler(stashHandler) 使用log123from flask import current_appcurrent_app.logger.info(&quot;hello world&quot;) 这样做的好处 可以多环境随意切换配置，而不用更改代码 日志配置在setting.py统一配置管理 完整代码autoapp.py: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788def create_app(config_filename): app = Flask(__name__) app.config.from_pyfile(config_filename) from yourapplication.model import db db.init_app(app) register_logging(app) from yourapplication.views.admin import admin from yourapplication.views.frontend import frontend app.register_blueprint(admin) app.register_blueprint(frontend) return appdef register_logging(app): app.config.setdefault(\"LOG_PATH\", \"application.log\") log_formatter = \"%(asctime)s [%(thread)d:%(threadName)s] %(filename)s:%(module)s:%(funcName)s in %(lineno)d] [%(levelname)s]: %(message)s\" app.config.setdefault(\"LOG_FORMATTER\", log_formatter) app.config.setdefault(\"LOG_MAX_BYTES\", 50 * 1024 * 1024) app.config.setdefault(\"LOG_BACKUP_COUNT\", 10) app.config.setdefault(\"LOG_INTERVAL\", 1) app.config.setdefault(\"LOG_WHEN\", \"D\") app.config.setdefault(\"LOG_LEVEL\", \"INFO\") formatter = logging.Formatter(app.config[\"LOG_FORMATTER\"]) # 将日志输出到文件 # 指定间隔时间自动生成文件的处理器 # 实例化TimedRotatingFileHandler # interval是时间间隔， # backupCount是备份文件的个数，如果超过这个个数，就会自动删除 # when是间隔的时间单位，单位有以下几种： # S 秒 # M 分 # H 小时、 # D 天、 # W 每星期（interval==0时代表星期一） # midnight 每天凌晨 timed_rotating_file_handler = TimedRotatingFileHandler( filename=app.config[\"LOG_PATH\"], interval=app.config[\"LOG_INTERVAL\"], when=app.config[\"LOG_WHEN\"], backupCount=app.config[\"LOG_BACKUP_COUNT\"], encoding=\"utf-8\", ) timed_rotating_file_handler.setFormatter(formatter) # 设置文件里写入的格式 timed_rotating_file_handler.setLevel(app.config[\"LOG_LEVEL\"]) # StreamHandler stream_handler = StreamHandler() stream_handler.setFormatter(formatter) stream_handler.setLevel(app.config[\"LOG_LEVEL\"]) # SMTPHandler mail_handler = DelaySMTPHandler( mailhost=app.config[\"MAILHOST\"], credentials=app.config[\"CREDENTIALS\"], fromaddr=app.config[\"FROMADDR\"], toaddrs=app.config[\"TOADDRS\"], subject=app.config[\"SUBJECT\"], ) mail_handler.setLevel(logging.ERROR) mail_handler.setFormatter(formatter) # 删除默认的handler # app.logger.removeHandler(default_handler) # 设置logger for logger in ( app.logger, logging.getLogger(\"sqlalchemy\"), logging.getLogger(\"werkzeug\"), ): logger.addHandler(stream_handler) logger.addHandler(timed_rotating_file_handler) if os.getenv(\"FLASK_ENV\") == \"production\": logger.addHandler(mail_handler) # set logger for elk # stash_handler = logstash.LogstashHandler( # app.config.get('ELK_HOST'), # app.config.get('ELK_PORT') # ) # root_logger.addHandler(stashHandler) settings.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147# -*- coding: utf-8 -*-\"\"\"Application configuration.\"\"\"import osBASE_DIR = os.path.dirname(__file__)class Config(object): # Base settings ################################################# DEBUG = False TESTING = False SECRET_KEY = \"\" BUNDLE_ERRORS = True # 日志配置 ############################################################### LOG_PATH = os.path.join(BASE_DIR, \"logs\", \"falling-wind-service.log\") LOG_FORMATTER = ( \"%(asctime)s [%(name)s] [%(thread)d:%(threadName)s] \" \"%(filename)s:%(module)s:%(funcName)s \" \"in %(lineno)d] \" \"[%(levelname)s]: %(message)s\" ) LOG_MAX_BYTES = 50 * 1024 * 1024 # 日志文件大小 LOG_BACKUP_COUNT = 10 # 备份文件数量 LOG_INTERVAL = 1 LOG_WHEN = \"D\" # 数据库配置 #################################################### SQLALCHEMY_ENGINE_OPTIONS = &#123; \"pool_timeout\": 10, # 默认链接超时时长 \"pool_size\": 10, # 数据库链接池大小 &#125; # 提供多库链接 使用其他库进行链接的时候需要使用bind指定那个库使用 SQLALCHEMY_BINDS = &#123;&#125; SQLALCHEMY_TRACK_MODIFICATIONS = True # Celery ################################################################## enable_utc = True timezone = \"Asia/Shanghai\" # or the actual content-type (MIME) accept_content = [\"application/json\"] # or the actual content-type (MIME) result_accept_content = [\"application/json\"] include = [\"app_tasks.user_tasks\"] result_expires = 3600 # JWT #################################################################### JWT_SECRET_KEY = \"\" # JWT_BLACKLIST_ENABLED = False # JWT_BLACKLIST_TOKEN_CHECKS = ['access', 'refresh']class Pro(Config): ENV = \"product\" # 日志 ################################################################## LOG_PATH = \"your application log path\" # DB ################################################################## DB_HOST = \"\" DB_PORT = 3306 DB_DATABASE = \"\" DB_USER = \"\" DB_PASSWORD = \"\" SQLALCHEMY_DATABASE_URI = \"mysql+pymysql://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;/&#123;&#125;\".format( DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_DATABASE ) # Redis #################################################### REDIS_URL = \"\" # Mail ######################################################## MAIL_SERVER = \"smtp.qq.com\" MAIL_PORT = 465 MAIL_USE_SSL = True MAIL_USERNAME = \"\" MAIL_PASSWORD = \"\" # Celery ########################################################### # Broker settings. broker_url = \"\" # Using the redis to store task state and results. result_backend = \"\" # JWT ############################################################### # JWT_ACCESS_TOKEN_EXPIRES = 60 * 60 JWT_SECRET_KEY = \"\" # SMTPHandler ###################################################### MAILHOST = (\"smtp.qq.com\", 465) CREDENTIALS = (\"\", \"\") FROMADDR = \"\" TOADDRS = [\"\"] SUBJECT = \"\" SECURE = (\"SSL\",)class Dev(Config): DEBUG = True ENV = \"dev\" # 日志 ################################################################## LOG_PATH = \"your path\" # DB #################################################################### DB_HOST = \"localhost\" DB_PORT = 3306 DB_DATABASE = \"\" DB_USER = \"\" DB_PASSWORD = \"\" SQLALCHEMY_DATABASE_URI = \"mysql+pymysql://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;/&#123;&#125;\".format( DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_DATABASE ) # Redis #################################################### REDIS_URL = \"\" # Mail ######################################################## MAIL_SERVER = \"smtp.qq.com\" MAIL_PORT = 25 MAIL_USE_TLS = True MAIL_USERNAME = \"\" MAIL_PASSWORD = \"\" # Celery ################################################################### # Broker settings. broker_url = \"\" # Using the redis to store task state and results. result_backend = \"\" # JWT ############################################################### JWT_ACCESS_TOKEN_EXPIRES = 60 * 60 JWT_SECRET_KEY = \"\" # SMTPHandler ###################################################### MAILHOST = (\"smtp.qq.com\", 465) CREDENTIALS = (\"\", \"\") FROMADDR = \"\" TOADDRS = [\"\"] SUBJECT = \"\"class Test(Config): TESTING = True DEBUG = True ENV = \"test\" app.py 1234567891011121314# -*- coding: utf-8 -*-\"\"\"Create an application instance.\"\"\"from autoapp import create_appimport osfrom extensions import celeryif os.getenv(\"FLASK_ENV\") == \"development\": app = create_app(\"settings.Dev\")elif os.getenv(\"FLASK_ENV\") == \"production\": app = create_app(\"settings.Pro\")else: raise EnvironmentError(\"Please set FLASK_ENV ！！！\")celery = celery 运行flaskwindows 12$ set FLASK_ENV&#x3D;development$ flask run Linux 12$ export FLASK_ENV&#x3D;development$ flask run Enjoy your code!","categories":[],"tags":[]},{"title":"20200331_ELKF环境搭建总结","slug":"20200331_ELKF环境搭建总结","date":"2020-04-10T07:00:34.295Z","updated":"2020-04-10T07:00:34.296Z","comments":true,"path":"2020/04/10/20200331_ELKF环境搭建总结/","link":"","permalink":"http://yoursite.com/2020/04/10/20200331_ELKF%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%80%BB%E7%BB%93/","excerpt":"","text":"ELK 环境搭建开始动手前的说明我搭建这一套环境的时候是基于docker搭建的，用到了docker-compose，所以开始前要先安装好docker 、 docker-compose，并简单的了解docker 、 docker-compose的用法。 前言ELK 是什么？ELK 指：ElasticSearch + Logstash + Kibana ELK 用来干什么？ELK 可以用来收集日志并进行日志分析，实现日志的统一管理，帮助开发人员和运维人员快速分析日志，快速发现问题。 当然它还有很多非常多实用功能，需要您去自行挖掘。 这里使用Filebeat进行日志收集并将收集上来的日志发送给ELK。 es: Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎。 kibana: Kibana 是通向 Elastic 产品集的窗口。 它可以在 Elasticsearch 中对数据进行视觉探索和实时分析。 logstash: Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中 filebeat: 轻量级收集日志的服务，并且可以将收集的日志发送给 es、logstash、kafka、redis filebeat 概览图 ELK日志数据收集时序图 接下来开始动手操作。 准备工作： 12345678$ mkdir ELK_pro$ cd ELK_pro$ touch docker-compose.yml$ touch Dockerfile$ touch filebeat.yml$ touch kibana.yml$ touch logstash-pipeline.conf$ touch logstash.yml ElasticSearch 环境搭建我是参考官网的例子直接写的docker-compose.yml，然后做了小的改动。下面是我改动之后的配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192version: \"3\"services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - xpack.security.enabled=true - xpack.security.authc.accept_default_password=true - xpack.security.transport.ssl.enabled=true - xpack.security.transport.ssl.verification_mode=certificate - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data - ./elastic-certificates.p12:/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ports: - 9200:9200 networks: - falling_wind es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - xpack.security.enabled=true - xpack.security.authc.accept_default_password=true - xpack.security.transport.ssl.enabled=true - xpack.security.transport.ssl.verification_mode=certificate - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data - ./elastic-certificates.p12:/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 networks: - falling_wind es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - xpack.security.enabled=true - xpack.security.authc.accept_default_password=true - xpack.security.transport.ssl.enabled=true - xpack.security.transport.ssl.verification_mode=certificate - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data - ./elastic-certificates.p12:/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 networks: - falling_windvolumes: data01: driver: local data02: driver: local data03: driver: localnetworks: falling_wind: driver: bridge 这个配置我是加了证书认证的。 下面请看证书生成方法： 进入docker (es01)： 12$ docker ps$ docker exec -it 容器ID或名称 /bin/sh 生成证书并copy 1234567$ cd bin$ elasticsearch-certutil ca$ elasticsearch-certutil cert --ca elastic-stack-ca.p12$ exit$ docker cp 容器ID:/usr/share/elasticsearch/elastic-certificates.p12 .# 注意：最后的点不要忘记了。 设置es01的密码： 123456$ docker ps$ docker exec -it 容器ID或名称 /bin/sh$ cd bin$ elasticsearch-setup-passwords interactive# 按照提示设置密码即可 kibana 环境搭建配置 kibana docker-compose.yml 1234567891011kibana: image: docker.elastic.co/kibana/kibana:7.6.1 container_name: kibana_7_61 ports: - \"5601:5601\" volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml networks: - falling_wind depends_on: - es01 kibana.yml 123456server.name: kibanaserver.host: \"0\"elasticsearch.hosts: [\"http://172.18.114.219:9200\"]xpack.monitoring.ui.container.elasticsearch.enabled: trueelasticsearch.username: your usernameelasticsearch.password: your password logsstash 环境搭建配置logsstash docker-compose.yml 12345678910logstash: image: docker.elastic.co/logstash/logstash:7.6.1 container_name: logstash_7_61 ports: - \"5044:5044\" volumes: - ./logstash.yml:/usr/share/logstash/config/logstash.yml - ./logstash-pipeline.conf:/usr/share/logstash/conf.d/logstash-pipeline.conf networks: - falling_wind logstash.yml 12path.config: /usr/share/logstash/conf.d/*.confpath.logs: /var/log/logstash logstash-pipeline.conf 12345678910111213141516171819202122input &#123; beats &#123; port &#x3D;&gt; 5044 codec &#x3D;&gt; json &#125; tcp &#123; port &#x3D;&gt; 8000 codec &#x3D;&gt; json &#125;&#125;output &#123; elasticsearch &#123; hosts &#x3D;&gt; [&quot;172.18.114.219:9200&quot;] index &#x3D;&gt; &quot;falling-wind&quot; user &#x3D;&gt; &quot;your username&quot; password &#x3D;&gt; &quot;your password&quot; &#125; stdout &#123; codec &#x3D;&gt; rubydebug &#125;&#125; filebeat 环境搭建配置 filebeat docker-compose.yml 123456789filebeat: container_name: filebeat_7_61 build: context: . dockerfile: Dockerfile volumes: - /var/logs:/usr/share/filebeat/logs networks: - falling_wind Dockerfile 12345FROM docker.elastic.co&#x2F;beats&#x2F;filebeat:7.6.1COPY filebeat.yml &#x2F;usr&#x2F;share&#x2F;filebeat&#x2F;filebeat.ymlUSER rootRUN chown root:filebeat &#x2F;usr&#x2F;share&#x2F;filebeat&#x2F;filebeat.ymlRUN chown root:filebeat &#x2F;usr&#x2F;share&#x2F;filebeat&#x2F;data&#x2F;meta.json 说明：官网上的Dockerfile最后还加了 USER filebeat，按理说应该不会出现什么问题，但是启动总是会报权限不足：/usr/share/filebeat/data/meta.json，所以我暂时将这一句去掉就好了。 filebeat.yml 123456789101112131415161718192021222324252627282930313233343536filebeat.inputs: - type: log paths: - /usr/share/filebeat/logs/falling-wind/*.log multiline.pattern: '^[[:space:]]' multiline.negate: false multiline.match: after tags: [\"falling-wind\"] - type: log paths: - /usr/share/filebeat/logs/celery/*.log multiline.pattern: '^[[:space:]]' multiline.negate: false multiline.match: after tags: [\"celery\"] - type: log paths: - /usr/share/filebeat/logs/gunicorn/*.log multiline.pattern: '^[[:space:]]' multiline.negate: false multiline.match: after tags: [\"gunicorn\"] - type: log paths: - /usr/share/filebeat/logs/supervisor/*.log tags: [\"supervisor\"]#============================= Filebeat modules ===============================filebeat.config.modules: # Glob pattern for configuration loading path: $&#123;path.config&#125;/modules.d/*.yml # Set to true to enable config reloading reload.enabled: trueoutput.logstash: hosts: [\"172.18.114.219:5044\"] 注意合并多行信息的配置： 将堆栈信息合并： 123multiline.pattern: '^[[:space:]]'multiline.negate: falsemultiline.match: after 总结一共需要的配置文件： docker-compose.yml Dockerfile： 构建filebeat镜像 elastic-certificates.p12：证书文件 filebeat.yml kibana.yml logstash-pipeline.conf logstash.yml docker-compose.yml 完整版： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126version: \"3\"services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - xpack.security.enabled=true - xpack.security.authc.accept_default_password=true - xpack.security.transport.ssl.enabled=true - xpack.security.transport.ssl.verification_mode=certificate - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data - ./elastic-certificates.p12:/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ports: - 9200:9200 networks: - falling_wind es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - xpack.security.enabled=true - xpack.security.authc.accept_default_password=true - xpack.security.transport.ssl.enabled=true - xpack.security.transport.ssl.verification_mode=certificate - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data - ./elastic-certificates.p12:/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 networks: - falling_wind es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.6.1 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - xpack.security.enabled=true - xpack.security.authc.accept_default_password=true - xpack.security.transport.ssl.enabled=true - xpack.security.transport.ssl.verification_mode=certificate - xpack.security.transport.ssl.keystore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 - xpack.security.transport.ssl.truststore.path=/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data - ./elastic-certificates.p12:/usr/share/elasticsearch/config/certificates/elastic-certificates.p12 networks: - falling_wind kibana: image: docker.elastic.co/kibana/kibana:7.6.1 container_name: kibana_7_61 ports: - \"5601:5601\" volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml networks: - falling_wind depends_on: - es01 logstash: image: docker.elastic.co/logstash/logstash:7.6.1 container_name: logstash_7_61 ports: - \"5044:5044\" volumes: - ./logstash.yml:/usr/share/logstash/config/logstash.yml - ./logstash-pipeline.conf:/usr/share/logstash/conf.d/logstash-pipeline.conf networks: - falling_wind filebeat: container_name: filebeat_7_61 build: context: . dockerfile: Dockerfile volumes: - /var/logs:/usr/share/filebeat/logs networks: - falling_windvolumes: data01: driver: local data02: driver: local data03: driver: localnetworks: falling_wind: driver: bridge Enjoy your code!","categories":[],"tags":[]},{"title":"20200414_Flask中的迭代器和生成器","slug":"20200414_Flask中的迭代器和生成器","date":"2020-04-10T07:00:34.295Z","updated":"2020-04-10T07:00:34.296Z","comments":true,"path":"2020/04/10/20200414_Flask中的迭代器和生成器/","link":"","permalink":"http://yoursite.com/2020/04/10/20200414_Flask%E4%B8%AD%E7%9A%84%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8/","excerpt":"","text":"前言面试的时候总是被问到迭代器、生成器、装饰器，一开始不知道怎么回答，然后查阅资料之后总算是有点认识了。 迭代器迭代器其实是一个实现了迭代器协议的容器对象。 它基于2个方法： __next__: 返回容器的下一个元素 __iter__: 返回迭代器本身 range()函数就是一个迭代器 接下来我模拟range写一个迭代器 1234567891011121314class Range: def __init__(self, start : int = 0, end : int = 10, step : int = 1): self.start = start self.end = end self.step = step def __next__(self): if self.start &gt; (self.end - self.step): raise StopIteration self.start += self.step return self.start def __iter__(self): return self 测试默认值： 12&gt;&gt;&gt; print([i for i in Range()])[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 测试非默认值，设置步长为3: 12&gt;&gt;&gt; print([i for i in Range(10, 50, 3)])[13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49] 可见Range对象是一个可以迭代的对象 迭代器跟生成器一般是结合使用的。 生成器基于yield语句，生成器可以暂停当前执行的函数，返回yield当前要返回的值，并保存上下文。 例如生成可以被3整除的数： 12345def divide_three(): a = 3 while True: yield a a += 3 测试： 123&gt;&gt;&gt; res &#x3D; divide_three()&gt;&gt;&gt; print([next(res) for i in range(20)])[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60] 这里调用了20次，理论上，如果你愿意，可以调用无限次，是不是很神奇。 来看看divide_three的类型： 12&gt;&gt;&gt; print(divide_three())&lt;generator object divide_three at 0x1116db550&gt; 现在是不是对迭代器、生成器有点感觉了。 Enjoy your code, good luck.","categories":[],"tags":[]},{"title":"20200317_Flask怎样快速切换运行环境","slug":"20200317_Flask怎样快速切换运行环境","date":"2020-04-10T07:00:34.294Z","updated":"2020-04-10T07:00:34.296Z","comments":true,"path":"2020/04/10/20200317_Flask怎样快速切换运行环境/","link":"","permalink":"http://yoursite.com/2020/04/10/20200317_Flask%E6%80%8E%E6%A0%B7%E5%BF%AB%E9%80%9F%E5%88%87%E6%8D%A2%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/","excerpt":"","text":"Flaks怎样快速切换运行环境配置先了解下Flask开发环境运行方式参考官网链接：https://flask.palletsprojects.com/en/1.1.x/quickstart/#a-minimal-application 运行app一般可以有两种方式： 命令行直接运行(推荐) 运行 app.py 脚本 命令行运行命令行运行方式： 指定app 123$ export FLASK_APP&#x3D;hello.py$ flask run * Running on http:&#x2F;&#x2F;127.0.0.1:5000&#x2F; 命令行运行方式： 指定ENV环境，(记住这种方式，后面会用到) 1234$ export FLASK_APP&#x3D;hello.py$ export FLASK_ENV&#x3D;development$ flask run * Running on http:&#x2F;&#x2F;127.0.0.1:5000&#x2F; 命令行运行方式： 指定DEBUG模式(指定 export FLASK_ENV=development 即开启debug模式，或者直接指定 export FLASK_DEBUG=1 ) 1234$ export FLASK_APP&#x3D;hello.py$ export FLASK_DEBUG&#x3D;1$ flask run * Running on http:&#x2F;&#x2F;127.0.0.1:5000&#x2F; 脚本运行编辑 app.py 1234567from autoapp import create_appapp = create_app('settings.Dev')if __name__ == \"__main__\": app.run() 运行 12$ python app.py * Running on http:&#x2F;&#x2F;127.0.0.1:5000&#x2F; 工厂模式下环境自由切换在工厂模式(create_app)下, 怎么实现 development｜production｜test 三种环境下配置的自由切换呢？ 首先工厂模式下应该存在这3个文件: app.py: 创建app实例的文件 autoapp.py: 存放工厂函数 settings.py: 存放系统配置 下面直接看代码： settings.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# -*- coding: utf-8 -*-\"\"\"Application configuration.\"\"\"class Config(object): # Base settings ############################################### DEBUG = False TESTING = False SECRET_KEY = \"it-is-secret\" # Log ######################################################### ... # Database #################################################### ...class Pro(Config): ENV = \"production\" # Log ######################################################### ... # Database #################################################### ...class Dev(Config): DEBUG = True ENV = \"development\" # Log ######################################################### ... # Database #################################################### ...class Test(Config): TESTING = True DEBUG = True ENV = \"test\" # Log ######################################################### ... # Database #################################################### ... autoapp.py 123456789101112from flask import Flaskdef create_app(config): \"\"\"Create application factory, as explained here: http://flask.pocoo.org/docs/patterns/appfactories/. :param config: The configuration object to use. \"\"\" app = Flask(__name__) app.config.from_object(config) return app app.py 12345678910111213# -*- coding: utf-8 -*-\"\"\"Create an application instance.\"\"\"from autoapp import create_appif os.getenv(\"FLASK_ENV\") == \"development\": app = create_app(\"settings.Dev\")elif os.getenv(\"FLASK_ENV\") == \"production\": app = create_app(\"settings.Pro\")elif os.getenv(\"FLASK_ENV\") == \"test\": app = create_app(\"settings.Test\")else: raise EnvironmentError(\"Please set FLASK_ENV ！！！\") 运行Flask 12345678910$ export FLASK_APP&#x3D;app:app$ export FLASK_ENV&#x3D;development$ flask run -p 8000 * Serving Flask app &quot;app:app&quot; (lazy loading) * Environment: development * Debug mode: on * Running on http:&#x2F;&#x2F;127.0.0.1:8000&#x2F; (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 118-853-556 未指定FLASK_EN运行 12345678910$ flask run * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: offTraceback (most recent call last): ...... ...... raise EnvironmentError(&quot;Please set FLASK_ENV ！！！&quot;)OSError: Please set FLASK_ENV ！！！ 生产环境使用gunicorn运行 1export FLASK_ENV&#x3D;production &amp;&amp; gunicorn app:app -c gunicorn.conf.py 注意：命令行方式执行都是在linux环境下，windows环境下命令可能稍微不同，将export换成set即可。 Enjoy your code.","categories":[],"tags":[]}],"categories":[],"tags":[]}